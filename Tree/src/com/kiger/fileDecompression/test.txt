package com.kiger.fileDecompression;

import java.io.*;
import java.util.*;

/**
 * @ClassName Decompress
 * @Description 解压类
 * @Author zk_kiger
 * @Date 2019/11/7 22:14
 * @Version 1.0
 */

public class Decompress {
    static final int CHAR_INDEX = 256;
    static final int BUFFER_SIZE = 128;
    // 每个字符对应哈夫曼编码的长度
    private int[] codelengths = new int[CHAR_INDEX];
    // 每个Huffman编码对应的字符
    private Map<String, Integer> huffmanMap = new HashMap<>();
    // 优先队列用于创建huffman树,自动从小到大排序结点
    private PriorityQueue<Node> queue = new PriorityQueue<>(new Comparator<Node>() {
        @Override
        public int compare(Node o1, Node o2) {
            return o1.getWeight() - o2.getWeight();
        }
    });

    public Decompress() {}

    public void deCompress(String fromPath, String toPath) {
        deCompress_(fromPath, toPath);
    }

    /**
     * 解压文件
     */
    private void deCompress_(String fromPath, String toPath) {

        // 1.读取文件里面的码表并还原码表
        // 2.根据权值重新构建Huffman树
        // 3.根据创建Huffman树遍历将字符写入文件
        System.out.println("开始解压缩文件...");
        decompressFile(fromPath, toPath);
        System.out.println("解压缩文件完成...");

    }


    // 读取文件内容,转为哈夫曼编码并解码写入文件
    private void decompressFile(String fromPath, String toPath) {
        // 前面256个字节存储的是每个字符的权值,从第257个字节读取
        try (
                BufferedInputStream bis = new BufferedInputStream(new FileInputStream(fromPath));
                BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(toPath))
                ){
            // 1.读取文件里面的码表并还原码表
            readHuffmanCode(bis);

            // 读取剩下的文件内容
            byte[] bytes = new byte[BUFFER_SIZE];
            int len;
            int lastIndex = -1;
